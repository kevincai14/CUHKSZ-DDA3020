{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "701a86c3",
   "metadata": {},
   "source": [
    "# Assignment 3: Coding Part\n",
    "**Course:** Machine Learning (DDA3020)\n",
    "\n",
    "<font color=Red>*Please enter your personal information (double-click this cell to edit)*</font>  \n",
    "**Name:**  \n",
    "**Student ID:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28c8d6",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This is the **coding section** of Assignment 3. It includes **two main questions**:\n",
    "\n",
    "- **Question 1:** K-Means Clustering\n",
    "- **Question 2:** Gaussian Mixture Models (GMM)\n",
    "\n",
    "Please follow the instructions in each cell. Complete the missing code in blocks marked with special comments such as:\n",
    "```python\n",
    "##########################\n",
    "## Write your code here ##\n",
    "##########################\n",
    "```\n",
    "\n",
    "Once completed, execute all cells and submit your final Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c6520",
   "metadata": {},
   "source": [
    "## Coding Question 1: K-Means Clustering\n",
    "\n",
    "In this question, you will implement the **core logic of K-Means** from scratch and evaluate the results using the **Silhouette score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec57668",
   "metadata": {},
   "source": [
    "### 1.1 Data Preparation\n",
    "We'll begin by generating a 2D synthetic dataset for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate 2D synthetic data with 3 clusters\n",
    "X, y_true = make_blobs(n_samples=300, centers=3, cluster_std=0.8, random_state=42)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=20)\n",
    "plt.title(\"Generated Dataset\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd1745",
   "metadata": {},
   "source": [
    "### 1.2 K-Means Core Implementation\n",
    "\n",
    "Complete the missing sections in the `KMeans` class to implement the core algorithm:\n",
    "1. **Assigning clusters** <font color=blue>(8 points)</font>  \n",
    "2. **Updating cluster centers** <font color=blue>(8 points)</font>  \n",
    "\n",
    "The method `fit()` combines these steps iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, n_clusters=3, max_iter=100):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "    def initialize_centers(self, X):\n",
    "        \"\"\"Randomly select K data points as initial cluster centers\"\"\"\n",
    "        np.random.seed(42)  # Reproducibility\n",
    "        random_idx = np.random.choice(X.shape[0], self.n_clusters, replace=False)\n",
    "        return X[random_idx]\n",
    "    \n",
    "    def assign_clusters(self, X, centers):\n",
    "        \"\"\"\n",
    "        Assign each point to the nearest cluster center.\n",
    "\n",
    "        Returns:\n",
    "            labels : ndarray of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        distances = np.zeros((X.shape[0], self.n_clusters))\n",
    "\n",
    "        ##########################\n",
    "        ## Write your code here ##\n",
    "        ##########################\n",
    "\n",
    "\n",
    "    def update_centers(self, X, labels):\n",
    "        \"\"\"\n",
    "        Recalculate cluster centers as the mean of points in each cluster.\n",
    "\n",
    "        Returns:\n",
    "            new_centers : ndarray of shape (n_clusters, n_features)\n",
    "        \"\"\"\n",
    "        new_centers = np.zeros((self.n_clusters, X.shape[1]))\n",
    "\n",
    "        ##########################\n",
    "        ## Write your code here ##\n",
    "        ##########################\n",
    "\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Run the full K-means algorithm.\"\"\"\n",
    "        self.centers = self.initialize_centers(X)\n",
    "        for _ in range(self.max_iter):\n",
    "            labels = self.assign_clusters(X, self.centers)\n",
    "            new_centers = self.update_centers(X, labels)\n",
    "            if np.allclose(self.centers, new_centers):\n",
    "                break\n",
    "            self.centers = new_centers\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf9b47",
   "metadata": {},
   "source": [
    "### 1.3 Visualization of K-Means Result\n",
    "Let's visualize the clusters and the final learned centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3)\n",
    "model.fit(X)\n",
    "predicted_labels = model.assign_clusters(X, model.centers)\n",
    "\n",
    "# Plot clustered points and centroids\n",
    "plt.scatter(X[:, 0], X[:, 1], c=predicted_labels, cmap='viridis', s=20)\n",
    "plt.scatter(model.centers[:, 0], model.centers[:, 1], c='red', s=200, marker='X')\n",
    "plt.title(\"K-Means Clustering Result\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85013ee0",
   "metadata": {},
   "source": [
    "### 1.4 Silhouette Score Evaluation\n",
    "\n",
    "Implement a function to compute the **Silhouette Score**, which measures how well samples are clustered.\n",
    "\n",
    "- $a(i)$: average intra-cluster distance\n",
    "- $b(i)$: average nearest-cluster distance\n",
    "\n",
    "Final score is:\n",
    "$$\n",
    "s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
    "$$\n",
    "<font color=blue>(10 points)</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc1eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_score(X, labels):\n",
    "    \"\"\"\n",
    "    Compute the mean Silhouette score.\n",
    "\n",
    "    Parameters:\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "\n",
    "    Returns:\n",
    "        float: Silhouette score in [-1, 1]\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    unique_labels = np.unique(labels)\n",
    "    silhouette_vals = np.zeros(n_samples)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        cluster_id = labels[i]\n",
    "\n",
    "        ##########################\n",
    "        ## Write your code here ##\n",
    "        ##########################\n",
    "\n",
    "\n",
    "\n",
    "score = silhouette_score(X, predicted_labels)\n",
    "print(f\"Silhouette Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26151832",
   "metadata": {},
   "source": [
    "## Coding Question 2: Gaussian Mixture Model (GMM)\n",
    "\n",
    "In this question, you will implement a **Gaussian Mixture Model (GMM)** using the **Expectation-Maximization (EM)** algorithm.\n",
    "\n",
    "A GMM is a probabilistic clustering model that assumes the data is generated from a mixture of $K$ Gaussian distributions:\n",
    "\n",
    "$$\n",
    "p(x) = \\sum_{k=1}^K \\pi_k \\cdot \\mathcal{N}(x \\mid \\mu_k, \\Sigma_k)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\pi_k$ is the mixing coefficient for the $k$-th Gaussian (with $\\sum_k \\pi_k = 1$)\n",
    "- $\\mu_k$, $\\Sigma_k$ are the mean and covariance of the $k$-th Gaussian\n",
    "\n",
    "You will:\n",
    "- Implement the EM algorithm (E-step and M-step)\n",
    "- Apply GMM to the same synthetic dataset as K-means\n",
    "- Visualize the clustering result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852413d",
   "metadata": {},
   "source": [
    "### 2.1 Multivariate Gaussian Density\n",
    "\n",
    "Before implementing GMM, we need a function to compute the multivariate Gaussian density:\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x \\mid \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{d/2} |\\Sigma|^{1/2}} \\exp\\left( -\\frac{1}{2}(x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right)\n",
    "$$\n",
    "\n",
    "> 🛠️ **Task**: Complete the function $gaussian_pdf(x, mean, cov)$ to compute the density value at point $x$  \n",
    "> The output should be a **scalar** representing $ p(x \\mid \\mu, \\Sigma) $\n",
    "\n",
    "<font color=blue>(8 points)</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mean, cov):\n",
    "    \"\"\"\n",
    "    Compute the multivariate normal density for a single sample x.\n",
    "\n",
    "    Parameters:\n",
    "        x    : (d,) array, input point\n",
    "        mean : (d,) array, Gaussian mean\n",
    "        cov  : (d, d) array, covariance matrix\n",
    "\n",
    "    Returns:\n",
    "        float: p(x | mean, cov)\n",
    "    \"\"\"\n",
    "    d = x.shape[0]\n",
    "\n",
    "    ##########################\n",
    "    ## Write your code here ##\n",
    "    ##########################\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c1a82",
   "metadata": {},
   "source": [
    "### 2.2 GMM Class & EM Algorithm\n",
    "\n",
    "You will now complete the core GMM algorithm by filling in the missing parts in the `e_step()` and `m_step()` methods.\n",
    "\n",
    "#### EM Steps Recap:\n",
    "\n",
    "- **E-step**: Compute responsibility $\\gamma_k^{(n)}$ for each data point <font color=blue>(8 points)</font>  :\n",
    "$$\n",
    "\\gamma_k^{(n)} = \\frac{\\pi_k \\cdot \\mathcal{N}(x^{(n)} \\mid \\mu_k, \\Sigma_k)}{\\sum_{j=1}^K \\pi_j \\cdot \\mathcal{N}(x^{(n)} \\mid \\mu_j, \\Sigma_j)}\n",
    "$$\n",
    "\n",
    "- **M-step**: Update model parameters based on current responsibilities <font color=blue>(8 points)</font>  :\n",
    "$$\n",
    "N_k = \\sum_n \\gamma_k^{(n)} \\quad \\quad\n",
    "\\mu_k = \\frac{1}{N_k} \\sum_n \\gamma_k^{(n)} x^{(n)}\n",
    "$$\n",
    "$$\n",
    "\\Sigma_k = \\frac{1}{N_k} \\sum_n \\gamma_k^{(n)} (x^{(n)} - \\mu_k)(x^{(n)} - \\mu_k)^T \\quad \\quad\n",
    "\\pi_k = \\frac{N_k}{N}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6adfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, n_components=3, max_iter=100):\n",
    "        self.K = n_components\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def initialize_params(self, X):\n",
    "        N, D = X.shape\n",
    "        np.random.seed(42)\n",
    "        idx = np.random.choice(N, self.K, replace=False)\n",
    "        self.means = X[idx]\n",
    "        self.covariances = np.array([np.eye(D)] * self.K)\n",
    "        self.weights = np.ones(self.K) / self.K\n",
    "\n",
    "    def e_step(self, X):\n",
    "        \"\"\"\n",
    "        E-step: compute responsibility matrix gamma (N x K)\n",
    "        return gamma\n",
    "        \"\"\"\n",
    "        N = X.shape[0]\n",
    "        gamma = np.zeros((N, self.K))\n",
    "\n",
    "        ##########################\n",
    "        ## Write your code here ##\n",
    "        ##########################\n",
    "        \n",
    "\n",
    "    def m_step(self, X, gamma):\n",
    "        \"\"\"\n",
    "        M-step: update weights, means, and covariances\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        Nk = np.sum(gamma, axis=0)\n",
    "        self.weights = Nk / N\n",
    "\n",
    "        ##########################\n",
    "        ## Write your code here ##\n",
    "        ##########################\n",
    "\n",
    "        \n",
    "\n",
    "    def fit(self, X):\n",
    "        self.initialize_params(X)\n",
    "        for _ in range(self.max_iter):\n",
    "            gamma = self.e_step(X)\n",
    "            self.m_step(X, gamma)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        gamma = self.e_step(X)\n",
    "        return np.argmax(gamma, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b3f9e",
   "metadata": {},
   "source": [
    "### 2.3 Visualize GMM Clustering Result\n",
    "\n",
    "Now that your GMM is implemented, run it on the dataset and visualize the learned clusters.\n",
    "\n",
    "> 🛠️ **Task 3**: Run your GMM on the same dataset and display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(n_components=3)\n",
    "gmm.fit(X)\n",
    "gmm_labels = gmm.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=gmm_labels, cmap='viridis', s=20)\n",
    "plt.scatter(gmm.means[:, 0], gmm.means[:, 1], c='red', s=200, marker='X')\n",
    "plt.title(\"GMM Clustering Result\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"KMeans Silhouette: {silhouette_score(X, predicted_labels):.3f}\")\n",
    "print(f\"GMM    Silhouette: {silhouette_score(X, gmm_labels):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
