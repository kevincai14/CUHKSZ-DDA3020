{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Question 3: Tree-based Models \n",
    "**Course Name:** Machine Learning (DDA3020)\n",
    "\n",
    "(30 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=Red>*Please enter your personal information (Double-click this block first)*</font>\n",
    "\n",
    "**Name:**\n",
    "\n",
    "**Student ID:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "In this question, you will use three tree-based models (Decision Tree, Bagging, and Random Forest) to solve a real problem, image classification. The tasks includes training models by different parameters, comparing the results of different models, and trying to find the best parameter combination. As a part of an assignment, your task is to **run all codes in this script and complete the parts marked with** <font color=Red>\\[TASK\\]</font>.\n",
    "\n",
    "### Dataset Introduction\n",
    "\n",
    "Since we will use a same dataset for both question 3 & 4, it's important to have an overall knowledge of this dataset. The dataset is called **Fashion-MNIST**, a member of the MNIST family, but I think it's more interesting. This dataset is an image classification task with ten categories, all of which are items from our daily lives. It consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image. It means that we can use 784 numbers (in the range of 0~255) to represent one image. More details can be found in https://github.com/zalandoresearch/fashion-mnist.\n",
    "\n",
    "OK. Now it's time to start, please read and run each block of codes in order, so that you will have a smooth experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Please do not modify the seed number here.\n",
    "np.random.seed(336)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't need to carefully read this block since it's just loading the dataset. Just run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind, subset=None):\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz'%kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz'%kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
    "    \n",
    "    if subset is not None:\n",
    "        selected_images, selected_labels = [], []\n",
    "        for label in range(10):\n",
    "            indices = np.where(labels == label)[0]\n",
    "            selected_indices = np.random.choice(indices, subset, replace=False)\n",
    "            selected_images.append(images[selected_indices])\n",
    "            selected_labels.append(labels[selected_indices])\n",
    "        images = np.concatenate(selected_images, axis=0)\n",
    "        labels = np.concatenate(selected_labels, axis=0)\n",
    "\n",
    "        paired = list(zip(images, labels))\n",
    "        random.shuffle(paired)\n",
    "        images, labels = zip(*paired)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we only use a subset of Fashion-MNIST dataset to reduce compuration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_mnist('./data/', kind='train', subset=100)\n",
    "X_test, y_test = load_mnist('./data/', kind='t10k', subset=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat running this block for several times to see different images with its label in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label index of this image is: 6\n",
      "The label name of this graph is: Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_names = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
    "idx = random.choice(range(0,len(X_test)))\n",
    "print(f\"The label index of this image is: {y_test[idx]}\")\n",
    "print(f\"The label name of this graph is: {label_names[y_test[idx]]}\")\n",
    "\n",
    "plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we use each pixel to represent different features of a data sample. It means that each sample will have 784 features to learn and 1 label to predict. The advantage is that you don't need to struggle on data processing but focus on training models and analyzing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=[f\"pixel_{i}\" for i in range(X_train.shape[1])])\n",
    "X_test = pd.DataFrame(X_test, columns=[f\"pixel_{i}\" for i in range(X_test.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both question 3 & 4, we only use one metric, **accuracy_score**. Here is a simple example about how to use this function from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "_y_true = [0,1,1,2,0]\n",
    "_y_pred = [1,1,2,2,0]\n",
    "accuracy_score(_y_true, _y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Write code to train Decision Tree Classification models with different **max_depth** (=1,2,...,9). Save the accuracy scores of **both** predicting train data and test data respectively in train_acc_dt and test_acc_dt. (For further analysis) <font color=Red>\\[TASK\\]</font> (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "train_acc_dt = []\n",
    "test_acc_dt  = []\n",
    "depth_list = range(1, 10)\n",
    "\n",
    "\n",
    "##########################\n",
    "## Write your code here ##\n",
    "##########################\n",
    "\n",
    "\n",
    "plt.plot(depth_list, train_acc_dt, marker=\".\", label='Training Accuracy')\n",
    "plt.plot(depth_list, test_acc_dt, marker=\".\", label='Testing Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Decision Tree: Accuracy vs Max Depth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will have a graph about accuracy scores of both train data and test data. **Please write your observations and findings here.** <font color=Red>\\[TASK\\]</font> (3 points)\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Write code to train Random Forest Classification models with different **max_depth** (=1,2,...,9). Save the accuracy scores of **both** predicting train data and test data respectively in train_acc_rf and test_acc_rf. (For further analysis) <font color=Red>\\[TASK\\]</font> (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "train_acc_rf = []\n",
    "test_acc_rf  = []\n",
    "depth_list = range(1, 10)\n",
    "\n",
    "\n",
    "##########################\n",
    "## Write your code here ##\n",
    "##########################\n",
    "\n",
    "\n",
    "plt.plot(depth_list, train_acc_rf, marker=\".\", label='Training Accuracy')\n",
    "plt.plot(depth_list, test_acc_rf, marker=\".\", label='Testing Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Random Forest: Accuracy vs Max Depth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will have a graph about accuracy scores of both train data and test data. **Try to compare this graph with the above one (Decision Tree's graph), and write your observations and findings here.** <font color=Red>\\[TASK\\]</font> (3 points)\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Write code to train **both Bagging and Random Forest** Classification models with different **n_estimators** (=10,20,50,100). Save the accuracy scores of predicting test data for both models respectively in bagging_test_acc and rf_test_acc. (For further analysis) <font color=Red>\\[TASK\\]</font> (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators_list = [10, 20, 50, 100]\n",
    "bagging_test_acc = []\n",
    "rf_test_acc = []\n",
    "\n",
    "\n",
    "##########################\n",
    "## Write your code here ##\n",
    "##########################\n",
    "\n",
    "\n",
    "plt.plot(n_estimators_list, bagging_test_acc, marker=\".\", label='Bagging Accuracy')\n",
    "plt.plot(n_estimators_list, rf_test_acc, marker=\".\", label='Random Forest Accuracy')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Bagging vs Random Forest')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will have a graph about accuracy scores of both models. **Please write your observations and findings here.** <font color=Red>\\[TASK\\]</font> (3 points)\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Write code to find the best parameter combination from **\\[n_estimators=50/100/200, max_depth=5/10/20/50\\]** by 4-fold cross validation. Please use GridSearchCV from sklearn to implement that. Output the best parameter combination and the test accuracy score with the best parameters. <font color=Red>\\[TASK\\]</font> (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "##########################\n",
    "## Write your code here ##\n",
    "##########################\n",
    "\n",
    "\n",
    "print(\"Best params:\", ________________)\n",
    "print(\"Test Accuracy with Best Model: \", _______________)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
